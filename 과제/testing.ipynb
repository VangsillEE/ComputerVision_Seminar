{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VangsillEE/ComputerVision_Seminar/blob/main/%EA%B3%BC%EC%A0%9C/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ecm7xHgOyyEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7012cf98-e2ab-4756-c3c4-3774f17c77c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot-Vzrh_yDXo",
        "outputId": "74247cf7-2f6a-4274-fd38-1be4aa42181a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CV_seminar_project\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/CV_seminar_project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yKZKqL53yRhj",
        "outputId": "20d58e0a-10b1-4b0d-9696-bcb236cbfb2e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/CV_seminar_project'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.학습한 가중치 불러오기"
      ],
      "metadata": {
        "id": "x4QA6MENzEEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "state_dict = torch.load('resnet50.pth')\n",
        "best_epoch = state_dict['epoch']\n",
        "best_test_acc = state_dict['test_acc']\n",
        "weights = state_dict['net']\n",
        "\n",
        "print(f'최종적으로 {best_epoch}번째 에포크에서 test셋 기준으로 {best_test_acc}를 달성하였습니다.')#변수로 바꾸기기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z60SUn7zBLS",
        "outputId": "912a0eb5-845f-4a07-e0de-5890443a1d2e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종적으로 11번째 에포크에서 test셋 기준으로 85.94를 달성하였습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. 학습한 가중치를 모델에 불러오기"
      ],
      "metadata": {
        "id": "Ym28WlQg0WqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' # device 배정\n",
        "torch.manual_seed(42)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(42)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j0Qlawj20n3K",
        "outputId": "c1791fb3-8402-4496-87bf-4e34071f2674"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models # 모델 라이브러리 함수\n",
        "\n",
        "resnet_50 = models.resnet50(pretrained=False).to(device) # 선행학습 여부 , finetunig한 부분이 있으니까까\n",
        "\n",
        "# finetuning\n",
        "import torch.nn as nn # 파이토치 뉴럴네트워크 layer 라이브러리\n",
        "resnet_50.fc = nn.Linear(resnet_50.fc.in_features, 3).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP-hlsoyzJVn",
        "outputId": "d65edd48-fbe7-43cb-c6a8-ae5602b3fcd4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습한 가중치 적용완료료\n",
        "resnet_50.load_state_dict(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmgB3uPN0ZSD",
        "outputId": "4be23e54-e782-44aa-a756-a58aa3ec0563"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. test셋의 최종 성능 확인하기\n",
        "과제\n",
        "> 모델은 100 epochs를 돌려서 만든 가중치를 이용함.            \n",
        "> test_loader를 생성하여, test_set의 최종 성능 평가        \n",
        "> 텐서보드는 자율로 이용하시오"
      ],
      "metadata": {
        "id": "G9wSh_n21FGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from dataset import Custom_dataset as C\n",
        "\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "# from dataset import Custom_dataset as C\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# import cv2\n",
        "# import os \n",
        "# import torch\n",
        "# import torchvision\n",
        "# from torchvision import transforms # 이미지 데이터 augmentation\n",
        "# import glob\n",
        "# import albumentations as A\n",
        "# from albumentations.pytorch.transforms import ToTensorV2 # albumentations 텐서화 함수\n",
        "\n",
        "\n",
        "root_path = '/content/drive/MyDrive/CV_seminar_project'\n",
        "\n",
        "test_transforms = A.Compose([\n",
        "    A.Resize(224,224),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0), # 텐서타입은 안해줌\n",
        "    ToTensorV2() # Normalize를 먼저하고 tensor화를 진행해야한다.\n",
        "])\n",
        "\n",
        "test_class = C(root_path=root_path, mode='test', transforms=test_transforms)\n",
        "test_loader = DataLoader(test_class, batch_size=4, shuffle = False, num_workers=0)\n"
      ],
      "metadata": {
        "id": "Qcur5gOHFRT2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF13p_cw-jlb",
        "outputId": "7145f673-8109-4d87-b60f-c64d6d75d68d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fc5d562fb80>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet_50\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "criterion =  nn.CrossEntropyLoss(reduction='sum') #add all samples in a mini-batch\n",
        "with torch.no_grad():\n",
        "  for test_img, test_label in test_loader:\n",
        "    test_img, test_label = test_img.to(device), test_label.to(device)\n",
        "    output = resnet_50(test_img) #모델에 입력\n",
        "    loss = criterion(output, test_label)\n",
        "    test_loss +=  loss.item()\n",
        "    pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "    correct += pred.eq(test_label.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "  test_loss, correct, len(test_loader.dataset),\n",
        "  100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsQfpKVD-64y",
        "outputId": "d7de3da8-6b0e-4abf-b06d-36c56a2ce9de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4131, Accuracy: 108/130 (83%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}